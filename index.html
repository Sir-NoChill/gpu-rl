<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CMPUT 605 - GPU Programming for Continuous Learning</title>
    <style>
        body {
            font-family: Georgia, serif;
            max-width: 900px;
            margin: 0 auto;
            padding: 20px;
            line-height: 1.6;
            color: #333;
            background: #fff;
        }
        
        h1 {
            color: #000;
            border-bottom: 2px solid #333;
            padding-bottom: 10px;
            margin-bottom: 20px;
            font-size: 1.8em;
        }
        
        h2 {
            color: #000;
            margin-top: 30px;
            margin-bottom: 15px;
            font-size: 1.3em;
            border-bottom: 1px solid #ccc;
            padding-bottom: 5px;
        }
        
        h3 {
            color: #333;
            margin-top: 20px;
            margin-bottom: 10px;
            font-size: 1.1em;
            font-weight: bold;
        }
        
        .header-info {
            background: #f5f5f5;
            padding: 15px;
            margin-bottom: 20px;
            border-left: 3px solid #666;
        }
        
        .header-info p {
            margin: 5px 0;
        }
        
        .course-structure {
            margin: 20px 0;
        }
        
        .course-structure ol {
            margin-left: 20px;
        }
        
        .course-structure li {
            margin: 10px 0;
        }
        
        .nested-list {
            margin-top: 10px;
            margin-left: 20px;
            list-style-type: lower-roman;
        }
        
        .timeline {
            background: #f9f9f9;
            padding: 15px;
            margin: 20px 0;
            border-radius: 5px;
        }
        
        .grading-table {
            width: 100%;
            margin: 20px 0;
            border-collapse: collapse;
        }
        
        .grading-table th, .grading-table td {
            padding: 10px;
            text-align: left;
            border: 1px solid #ddd;
        }
        
        .grading-table th {
            background: #f0f0f0;
            font-weight: bold;
        }
        
        .grading-table tr:hover {
            background: #f5f5f5;
        }
        
        a {
            color: #0066cc;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        .date-revised {
            font-style: italic;
            color: #666;
            margin-bottom: 15px;
        }
        
        .emphasis {
            font-weight: bold;
            color: #000;
        }
        
        .section {
            margin: 30px 0;
        }
        
        ul {
            margin-left: 20px;
        }
        
        li {
            margin: 8px 0;
        }
        
        .project-desc {
            background: #fafafa;
            padding: 15px;
            border: 1px solid #e0e0e0;
            margin: 15px 0;
        }
    </style>
</head>
<body>
    <div class="date-revised">Revised January 2, 2026</div>
    
    <h1>CMPUT 605: GPU Programming for Sparse and Adaptive Networks</h1>
    
    <div class="header-info">
        <p><strong>TERM:</strong> Winter 2026</p>
        <p><strong>TIME:</strong> TBD - two 1:20 minute sessions per week</p>
        <p><strong>INSTRUCTOR:</strong> TBD</p>
        <p><strong>LOCATION:</strong> TBD</p>
    </div>

    <h2>Calendar Description</h2>
    <p>
        Independent study course focusing on the use of GPGPU techniques to advance sparse neural networks, 
        evolving network topologies, and streaming learning by leveraging modern GPGPU hardware and developing 
        compiler transformations to further leverage existing infrastructure for these learning paradigms.
    </p>

    <h2>Course Description and Goals</h2>
    <p>
        This course provides an in-depth exploration of GPU programming techniques and their application to 
        sparse neural networks, adaptive network structures, and streaming learning problems. Students will gain 
        hands-on experience with CUDA, HIP, and potentially OpenXLA/SPIRV, while developing expertise in GPU 
        profiling, optimization, and multi-GPU scaling. The course covers the underlying architecture of modern 
        GPUs, current advances in GPU hardware design, and compiler-based approaches to optimization. We are 
        specifically interested in learning how GPUs can be used to accelerate sparse neural networks, evolving 
        topology, and streaming learning. The course bridges theoretical understanding with practical implementation 
        through collaborative assignments and a substantial research project.
    </p>
    
    <p>
        By the end of this course, students will be able to:
    </p>
    <ul>
        <li>Write and optimize GPU kernels using CUDA and HIP</li>
        <li>Understand modern GPU architecture and recent hardware advances</li>
        <li>Profile GPU applications and identify performance bottlenecks using profiling tools and compiler-based instrumentation</li>
        <li>Debug GPU code using modern profiling tools</li>
        <li>Apply compiler transformations to address common GPU programming issues</li>
        <li>Analyze tradeoffs between different algorithmic approaches for GPU execution</li>
        <li>Scale implementations to multi-GPU systems</li>
        <li>Design and optimize kernels for non-standard computational patterns</li>
    </ul>
    
    <p>
        <strong>Learning Objectives by Student Background:</strong>
    </p>
    <ul>
        <li><strong>For Deep Learning Students:</strong> Develop the ability to implement and optimize custom GPU kernels for novel neural network architectures, understand hardware constraints that shape algorithm design, and bridge the gap between algorithmic innovation and efficient execution.</li>
        <li><strong>For Computer Architecture Students:</strong> Gain practical experience with GPU programming models, understand how compiler transformations map high-level code to GPU hardware, and explore the design space of GPU architectures through performance analysis and optimization.</li>
    </ul>

    <h2>Course Structure</h2>
    <div class="course-structure">
        <ol>
            <li>
                <span class="emphasis">The Ins and Outs of CUDA/HIP</span>
                <ol class="nested-list">
                    <li>Implementation of common data structures and algorithms using CUDA, HIP and potentially OpenXLA/SPIRV</li>
                    <li>GPU profiling tools for debugging algorithms and data structures</li>
                    <li>Understanding profiling tool internals and compiler-based instrumentation techniques</li>
                    <li>Compiler transformations for addressing common GPU programming challenges (memory coalescing, bank conflicts, divergence)</li>
                    <li>Scaling algorithms and tools to multi-GPU systems/clusters</li>
                </ol>
            </li>
            <li>
                <span class="emphasis">Sparsity, Dynamic Networks, and Hardware-Underexplored Approaches</span>
                <ol class="nested-list">
                    <li>Review of research in sparse neural networks and dynamic connectivity</li>
                    <li>Understanding what has been done in evolving network structures</li>
                    <li>Analysis of streaming learning and sequential data challenges</li>
                    <li>How data movement patterns and code transformations enable efficient sparsity in hardware</li>
                    <li>Multi-GPU communication and partitioning strategies for sparse and dynamic workloads</li>
                </ol>
            </li>
            <li>
                <span class="emphasis">Course Project</span>
                <ol class="nested-list">
                    <li>Development of a course project throughout the term</li>
                    <li>Production of a comprehensive writeup for evaluation</li>
                </ol>
            </li>
        </ol>
    </div>

    <h2>Course Timeline</h2>
    <div class="timeline">
        <h3>Phase 1 & 2 (January 2026 - Mid-February)</h3>
        <p>
            Overlapping coverage of GPU programming fundamentals and literature review:
        </p>
        <ul>
            <li><strong>Day 1 (weekly):</strong> Discussion of the week's research papers</li>
            <li><strong>Day 2 (weekly):</strong> Algorithm implementation progress and technical discussions</li>
        </ul>
        
        <h3>Phase 3 (Mid-February - April 2026)</h3>
        <p>
            Dedicated time for course project development, with bi-weekly progress reviews and implementation refinement.
        </p>
    </div>

    <h2>Grading Scheme</h2>
    <table class="grading-table">
        <thead>
            <tr>
                <th>Component</th>
                <th>Description</th>
                <th>Weight</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td>GPU Programming Assignments</td>
                <td>Three collaborative assignments in GPU programming (potentially to be integrated into future CMPUT 429 or GPU programming courses)</td>
                <td>30%</td>
            </tr>
            <tr>
                <td>Paper Discussions & Participation</td>
                <td>Active participation in weekly paper discussions and class activities</td>
                <td>30%</td>
            </tr>
            <tr>
                <td>Course Project</td>
                <td>Research project bridging gaps in streaming learning/RL/useful GPU algorithms or implementations</td>
                <td>40%</td>
            </tr>
        </tbody>
    </table>

    <h2>Detailed Course Plan</h2>
    <div class="section">
        <h3>Weeks 1-6: GPU Programming Foundations</h3>
        <ul>
            <li>CUDA/HIP programming fundamentals</li>
            <li>Memory management and optimization techniques</li>
            <li>Kernel optimization strategies</li>
            <li>Introduction to GPU profiling tools (NSight, ROCprof)</li>
            <li>Implementation of common data structures and algorithms</li>
            <li>Weekly paper discussions on relevant RL topics</li>
        </ul>

        <h3>Weeks 7-9: Advanced GPU Techniques</h3>
        <ul>
            <li>Multi-GPU programming and communication</li>
            <li>GPU architecture deep dive</li>
            <li>Review of existing sparse and dynamic networks techniques for GPUs</li>
        </ul>

        <h3>Weeks 10-14: Project Development</h3>
        <ul>
            <li>Project proposal and design</li>
            <li>Implementation and iterative development</li>
            <li>Performance analysis and optimization</li>
            <li>Final presentation and writeup</li>
        </ul>
    </div>

    <h2>Key Topics to be Covered</h2>
    <div class="section">
        <h3>GPU Programming and Performance Analysis</h3>
        <ul>
            <li>CUDA and HIP programming fundamentals</li>
            <li>GPU architecture: compute units, memory hierarchies, warp schedulers, tensor cores</li>
            <li>Recent advances in GPU hardware design (Hopper, RDNA3, and beyond)</li>
            <li>Memory hierarchies and optimization techniques</li>
            <li>Kernel optimization strategies</li>
            <li>Warp-level primitives and cooperative groups</li>
            <li>Profiling tools: NSight Systems, NSight Compute, ROCprof</li>
            <li>Profiler internals and compiler-based instrumentation approaches</li>
            <li>Understanding memory access patterns and their performance implications</li>
            <li>Dynamic parallelism and unified memory</li>
            <li>Multi-GPU programming and communication (NCCL)</li>
            <li>Compiler transformations for performance optimization</li>
        </ul>

        <h3>Hardware-Underexplored Algorithmic Directions</h3>
        <ul>
            <li><strong>Sparsity:</strong> Sparse neural networks, structured vs. unstructured sparsity, GPU implementations</li>
            <li><strong>Dynamic Connectivity:</strong> Networks where connection patterns change during training/inference</li>
            <li><strong>Evolving Structures:</strong> Neural architectures that grow, shrink, or restructure over time</li>
            <li><strong>Streaming Learning:</strong> True online learning with batch size = 1, sequential data streams</li>
            <li>Review of existing research and implementations in these areas</li>
            <li>Analysis of computational challenges and GPU optimization opportunities</li>
        </ul>

        <h3>Tools and Infrastructure</h3>
        <ul>
            <li>NSight Systems and NSight Compute</li>
            <li>ROCprof and ROCtracer</li>
            <li>NVCC (NVIDIA CUDA Compiler) and HIPCC (HIP Compiler)</li>
            <li>Compiler toolchains and their role in GPU code generation</li>
            <li>GPU cluster job scheduling (SLURM)</li>
            <li>Custom kernel development for non-standard operations</li>
            <li>Exploring portability strategies and bridging the CUDA ecosystem</li>
        </ul>
    </div>

    <h2>Project Guidelines</h2>
    <div class="project-desc">
        <p>
            The course project should demonstrate mastery of GPU programming techniques while contributing 
            to the fields of sparse neural networks, streaming learning, or adaptive network structures. 
            Potential project areas include:
        </p>
        <ul>
            <li>GPU-accelerated implementations of sparse neural network algorithms</li>
            <li>Optimization of existing frameworks for GPU execution of dynamic or evolving networks</li>
            <li>Development of GPU-efficient data structures for sparse connectivity patterns</li>
            <li>Multi-GPU scaling strategies for sparse or adaptive network training</li>
            <li>Compiler transformations for automatic GPU optimization of sparse learning algorithms</li>
            <li>Streaming/online learning: Profiling batch size = 1 training; investigating GPU utilization in sequential learning scenarios</li>
            <li>Benchmarking suites for GPU-accelerated sparse and adaptive networks</li>
        </ul>
        <p>
            Projects will be evaluated based on technical depth, innovation, implementation quality, 
            performance analysis, and the clarity of the final writeup.
        </p>
    </div>

    <h2>Prerequisites</h2>
    <ul>
        <li>Strong programming skills in C/C++ or Python</li>
        <li>Familiarity with machine learning concepts</li>
        <li>Basic understanding of computer architecture</li>
        <li>Experience with Linux/Unix environments</li>
    </ul>

    <h2>Resources</h2>
    <ul>
        <li>NVIDIA CUDA Programming Guide</li>
        <li>AMD ROCm Documentation</li>
        <li>Selected research papers (to be provided)</li>
        <li>Access to GPU compute cluster</li>
        <li>Course repository with starter code and examples</li>
    </ul>

    <footer style="margin-top: 50px; padding-top: 20px; border-top: 1px solid #ccc; color: #666; font-size: 0.9em;">
        <p>Course webpage maintained by the Department of Computing Science, University of Alberta</p>
        <p>For questions or concerns, please contact the course instructor.</p>
    </footer>
</body>
</html>
